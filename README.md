# Data Cleaning and Exploratory Data Analysis Project

This project showcases the process of cleaning and EDA in a CSV dataset using SQL queries. The dataset involves layoffs and was cleaned by performing several SQL operations,
and then performed EDA on it.

## Files:
- `layoffs.csv`: The original dataset.
- `Data_cleaning_Project.sql`: The SQL queries used to clean the dataset.
- `Exploratory_Data_Analysis_Project.sql`: The SQL queries used to Explore and Analyze the dataset.

## SQL Operations Performed:
- Data cleaning operations including:
  - Removing duplicate entries
  - Normalizing data formats
  - Handling missing data
  - Filtering and aggregating data for analysis

## Analysis Steps
1. **Data Cleaning**: Removal of duplicates, handling null values, and ensuring data consistency.
2. **Summary Statistics**: Calculating the total number of layoffs, average layoffs per company, and industry-wise layoffs.
3. **Trend Analysis**: Exploring the trend of layoffs over time and identifying peak periods.
4. **Industry-Wise Insights**: Analyzing the layoffs across various industries to understand the sectors most impacted.
5. **Geographical Analysis**: Identifying regions with the highest number of layoffs.
6. **Additional Insights**: Using SQL to uncover any correlations between factors like company size, industry type, and layoff frequency.

## How to Use:
1. Clone the repository: 
   ```bash
   git clone https://github.com/yourusername/Data-Cleaning-Project.git
   ```
2. Import the CSV into your SQL database.
3. Run the queries from `Data_cleaning_Project.sql` in your SQL environment to clean the data.
3. Run the queries from `Exploratory_Data_Analysis_Project.sql` in your SQL environment to clean the data.
